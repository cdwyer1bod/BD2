{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collection of all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score\n",
    "#from vectorize import get_pos_tag, vectorize_word, vectorize_pos_n, get_freqs\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subjectivity and Polarity using Pattern.en\n",
    "\n",
    "Values between 0.0 (objective) and +1.0 (subjective). Polarity between -1.0 and 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pattern.en import sentiment\n",
    "def subjectivity(sentence):\n",
    "    # sentiment(sentence): Returns a (polarity, subjectivity)-tuple.\n",
    "    return sentiment(sentence)[1]\n",
    "\n",
    "def polarity(sentence): return sentiment(sentence)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjectivity(\"in my opinion the cat is the best creature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment using VADER\n",
    "\n",
    "Continuous range between -1.0 (extremely negative) and +1.0 (extremely positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vaderSentiment\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "def sentiment_analyzer_scores(sentence):\n",
    "    analyser = SentimentIntensityAnalyzer()\n",
    "    score = analyser.polarity_scores(sentence)\n",
    "    return score['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5423"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_analyzer_scores(\"phone is bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compound': -0.5423, 'neg': 0.636, 'neu': 0.364, 'pos': 0.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyser = SentimentIntensityAnalyzer()\n",
    "analyser.polarity_scores(\"phone is bad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modality Pattern.en\n",
    "\n",
    "The mood() function returns either INDICATIVE, IMPERATIVE, CONDITIONAL or SUBJUNCTIVE for a given parsed Sentence. See the table below for an overview of moods.\n",
    "\n",
    "The modality() function returns the degree of certainty as a value between -1.0 and +1.0, where values &gt; +0.5 represent facts. For example, \"I wish it would stop raining\" scores -0.35, whereas \"It will stop raining\" scores +0.75. Accuracy is about 68% for Wikipedia texts.\n",
    "\n",
    "<img src=\"../pictures/modality_table.png\" width=\"650\" height=\"350\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('indicative', 0.1111111111111111)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pattern.en import parse, Sentence, parse\n",
    "from pattern.en import modality, mood\n",
    "def modal(s):\n",
    "    s = parse(s, lemmata=True)\n",
    "    s = Sentence(s)\n",
    "    return mood(s), modality(s)\n",
    "modal(\"Some amino acids tend to be acidic while others may be basic.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Readability using Flesch-Kincaid Grade Level Formula\n",
    "\n",
    "0.39 * (total words/ total sentences) + 11.8 (total syllables/ total words) -15.59 = US grade level readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import cmudict\n",
    "d = cmudict.dict()\n",
    "\n",
    "def nsyl(word):\n",
    "    try:\n",
    "        return [len(list(y for y in x if y[-1].isdigit())) for x in d[word.lower()]]\n",
    "    except KeyError:\n",
    "        #if word not found in cmudict\n",
    "        return syllables(word)\n",
    "def syllables(word):\n",
    "    #referred from stackoverflow.com/questions/14541303/count-the-number-of-syllables-in-a-word\n",
    "    count = 0\n",
    "    vowels = 'aeiouy'\n",
    "    word = word.lower()\n",
    "    if word[0] in vowels:\n",
    "        count +=1\n",
    "    for index in range(1,len(word)):\n",
    "        if word[index] in vowels and word[index-1] not in vowels:\n",
    "            count +=1\n",
    "    if word.endswith('e'):\n",
    "        count -= 1\n",
    "    if word.endswith('le'):\n",
    "        count += 1\n",
    "    if count == 0:\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "def FKGL(s, total_sents=1):\n",
    "    try: num_syllables = nsyl(s)[0]\n",
    "    except: num_syllables = nsyl(s)\n",
    "    total_words = len(s.split())\n",
    "    return 0.39*total_words/total_sents + 11.8*num_syllables/total_words - 15.59"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening All Files for Corpus Features\n",
    "\n",
    "Open all files for assertives, entailments, hedges etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrispath = \"/Users/chrisdwyer/Bias_Detection/2013_Linguistic_Models_Paper/npov-edits/LinguisticModels_bias_detection\"\n",
    "darcypath = 'asdf'\n",
    "path_to_use = chrispath\n",
    "\n",
    "bias_lexicon_file = open(path_to_use+'/bias-lexicon/bias-lexicon.txt','r')\n",
    "implicatives_file = open(path_to_use+'/bias_related_lexicons/implicatives_karttunen1971.txt','r')\n",
    "assertives_file = open(path_to_use+'/bias_related_lexicons/assertives_hooper1975.txt','r')\n",
    "factives_file = open(path_to_use+'/bias_related_lexicons/factives_hooper1975.txt','r')\n",
    "hedges_file = open(path_to_use+'/bias_related_lexicons/hedges_hyland2005.txt','r')\n",
    "other_file = open(path_to_use+'/bias_related_lexicons/other_lexicons.txt','r')\n",
    "report_verbs_file = open(path_to_use+'/bias_related_lexicons/report_verbs.txt','r')\n",
    "entailments_file = open(path_to_use+'/entailments/reverb_global_clsf_all_tncf_lambda_0.1.txt','r')\n",
    "strong_subjectives_file = open(path_to_use+'/subjectivity_clues/strongsubj.csv','r')\n",
    "weak_subjectives_file = open(path_to_use+'/subjectivity_clues/weaksubj.csv','r')\n",
    "\n",
    "bias_lexicon = bias_lexicon_file.read().strip().split('\\n')\n",
    "assertives = assertives_file.read().strip().split('\\n')[7:]\n",
    "factives = factives_file.read().strip().split('\\n')[7:]\n",
    "hedges = hedges_file.read().strip().split('\\n')[7:]\n",
    "other_lexicon = other_file.read().strip().split('\\n')\n",
    "report_verbs = report_verbs_file.read().strip().split('\\n')[9:]\n",
    "entailments_prestrip = entailments_file.read().strip().split('\\n')\n",
    "\n",
    "# Strong/weak subjectives\n",
    "# TODO: Word, Priorpolarity (PP) headers\n",
    "strong_subjectives = list(set(strong_subjectives_file.read().strip().split('\\n')))\n",
    "weak_subjectives = list(set(weak_subjectives_file.read().strip().split('\\n')))\n",
    "strong_subjectives_withPP = [strong_subjectives[i].split(',') for i in range(len(strong_subjectives))]\n",
    "weak_subjectives_withPP = [weak_subjectives[i].split(',') for i in range(len(weak_subjectives))]\n",
    "strong_subjectives_list, weak_subjectives_list = [], []\n",
    "for ss_row, ws_row in zip(strong_subjectives_withPP, weak_subjectives_withPP):\n",
    "    strong_subjectives_list.append(ss_row[0])\n",
    "    weak_subjectives_list.append(ws_row[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entailment Data\n",
    "\n",
    "Use Entailment function to clean data and get it into a list format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entailment_sorter(arr, length_entailing_predicate = 1, orderXY=True):\n",
    "    '''\n",
    "    Takes entailment dataset and distills it into usable information. Use params to get\n",
    "    the output you want. X 'word' Y = True means first argument is X, second is Y. False\n",
    "    means first argument is Y and second is X. \n",
    "    If orderXY = True it includes the last 2 headers:\n",
    "    Entailing Predicate, Entailed Predicate, X.Y=T/F Entailing Pred., X.Y=T/F Entailed Pred.\n",
    "    '''\n",
    "    # TODO: what happens when we want a longer length_entailing_predicate?\n",
    "    if orderXY:\n",
    "        data = []\n",
    "        for e in arr:\n",
    "            x, y = e.split('\\t')\n",
    "            if len(x.split()) <= length_entailing_predicate:\n",
    "                x_arg, y_arg = True, True\n",
    "                if '@R@' in x: x_arg = False\n",
    "                if '@R@' in y: y_arg = False\n",
    "                data.append([x.replace('@R@',''), y.replace('@R@',''), x_arg, y_arg])\n",
    "        df = pd.DataFrame(data, columns=['Entailing Predicate','Entailed Predicate',\n",
    "                                         'X.Y=T/F Entailing Pred.','X.Y=T/F Entailed Pred.'])\n",
    "        return df\n",
    "    else:\n",
    "        data = []\n",
    "        for e in arr:\n",
    "            x, y = e.split('\\t')\n",
    "            if len(x.split()) <= length_entailing_predicate:\n",
    "                data.append([x.replace('@R@',''), y.replace('@R@','')])\n",
    "        df = pd.DataFrame(data, columns=['Entailing Predicate','Entailed Predicate'])\n",
    "        return df\n",
    "    \n",
    "entailments = entailment_sorter(entailments_prestrip, length_entailing_predicate = 1, \n",
    "                                orderXY=True)\n",
    "entailing_predicates = list(entailments['Entailing Predicate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize Corpus Features: isInList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isInList(dictionaries, word, n_gram):\n",
    "    '''\n",
    "    Pass in array of dictionaries, word under instpection and n_gram of words - \n",
    "    either [3,4,5]-gram length.\n",
    "    Returns True/False vector if word and if surrounding words are in the dictionary. \n",
    "    Vector length is 2 x (# of dictionaries), first T/F is if word is in dictionary, second\n",
    "    T/F if any of the immediately surrounding word(s) is in dictionary.\n",
    "    Make sure you input dictionaries in the correct order.\n",
    "    True = 1, False = 0\n",
    "    '''\n",
    "    tf_vector = []\n",
    "    len_ngram, words_ngram = len(n_gram.split()), np.array(n_gram.split())\n",
    "    surrounding_words = []\n",
    "    if len_ngram == 3:\n",
    "        if word == words_ngram[0]: surrounding_words.append(words_ngram[1])\n",
    "        else: surrounding_words.append(words_ngram[-2])\n",
    "    elif len_ngram == 4:\n",
    "        # n_gram is 4 words long, target word is either in position 2 or 3 \n",
    "        word_index = np.where(word == words_ngram)[0]\n",
    "        if 1 in word_index: # target word is 2nd word\n",
    "            surrounding_words.append(words_ngram[0])\n",
    "            surrounding_words.append(words_ngram[2])\n",
    "        elif 2 in word_index: # target word is 3rd word\n",
    "            surrounding_words.append(words_ngram[1])\n",
    "            surrounding_words.append(words_ngram[3])\n",
    "        # only issue is if the target word repeats?\n",
    "    elif len_ngram == 5:\n",
    "        # n_gram is 5 words long, target word is in the middle\n",
    "        surrounding_words.append(words_ngram[1]) \n",
    "        surrounding_words.append(words_ngram[3])\n",
    "\n",
    "    for dictionary in dictionaries:\n",
    "        if word in dictionary: tf_vector.append(1)\n",
    "        else: tf_vector.append(0)\n",
    "        for surrounding_word in surrounding_words:\n",
    "            if surrounding_word in dictionary:\n",
    "                tf_vector.append(1)\n",
    "                break\n",
    "            else:\n",
    "                # If last word in surrounding_words list, then neither word is in dictionary\n",
    "                if surrounding_word == surrounding_words[-1]:\n",
    "                    tf_vector.append(0)\n",
    "                    break\n",
    "    return tf_vector\n",
    "\n",
    "def isInBiasLexicon(word,dictionary=bias_lexicon):\n",
    "    if word in dictionary: return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
